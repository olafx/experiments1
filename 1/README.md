# 1

NVIDIA video and image encoding and decoding.

This is in 'preparation' for a potential project in generally relativistic raytracing, where TIFF images are suited to store renders with unorthodox color data, with multiple subfiles for e.g. different orbit numbers.

https://docs.nvidia.com/cuda/nvtiff/userguide.html\
https://developer.nvidia.com/nvjpeg\
https://docs.nvidia.com/cuda/nvjpeg/index.html\
https://developer.nvidia.com/nvcomp\
https://github.com/NVIDIA/nvcomp/blob/main/README.md\
https://github.com/NVIDIA/CUDALibrarySamples/tree/master

NVIDIA has tools for image and encoding and decoding, which are ever expanding. E.g. there's nvJPEG and nvTIFF, and at some point hopefully nvPNG. Related to these is nvCOMP, a compression library. JPEG specifies a compression standard, so nvJPEG, like nvCOMP, is a compression library. As far as we know, nvJPEG is also unique in that accelerators have hardware dedicated to this compression algorithm. TIFF images can use various compression algorithms, like JPEG (so nvTIFF depends on nvJPEG), Deflate (which is part of nvCOMP, so nvTIFF depends on nvCOMP), and LZW (which is not part of nvCOMP for some reason, so nvTIFF implements LZW).\
We're interested here in nvTIFF in particular for lossless image storage. nvTIFF only supports encoding via LZW for some reason, so we will encode LZW TIFF images. We will use libpng (easy to use and well known) for encoding and decoding PNGs, as a means of testing. Testing amounts to decoding PNGs and encoding TIFFs, and vice versa.

We encode TIFFs with a bandwidth on the order of hundreds of MB/s, for 3840x2160 24-bit RGB images, which have a size around 10 MB. We find that most of the time is spent encoding. The encoding bandwidth is not that fast, on the order of hundreds of MB/s. Yet the device is working hard. It's not clear to us why it's so slow, nvCOMP generally has better results for similar compression algorithms, e.g. LZ4 has ~4 GB/s bandwidth for textures. So ours is ~10 times slower than expected. But it's hard to judge these things, it's unclear what exact compression algorithm is used, that's not really the user's concern anyway, and the library's primary practical usage is decoding, not encoding. Our performance results, appropriately scaled, are similar to those reported by NVIDIA for the GV100, in https://github.com/NVIDIA/CUDALibrarySamples/tree/master/nvTIFF/nvTIFF-Decode-Encode.

We decode TIFFs much faster, on the order of 1 GB/s, which is in line with what's expected. This is for LZW in particular. Half the time is spent allocating for typical 3840x2160 24-bit RGB images, so it would be beneficial practically to reuse the buffer, unlike for encoding, where it's negligible.

We find that the TIFFs put out by FFMPEG are of a format that nvTIFF does not like, we get the NVTIFF_STATUS_TIFF_NOT_SUPPORTED error, for some reason. This stuff is not as standardized as it should be, there's really not much we can do about this. But it does decode TIFFs written by nvTIFF. nvTIFF supports a number of compression algorithms. FFMPEG more probably than not, uses LZW, which should be no problem. So the (slight) issue is unclear, but we can just decode nvTIFF-encoded images instead.

We notice that file sizes vary significantly. After decoding a PNG, encoding it as a TIFF, decoding the TIFF, and finally encoding the PNG, the PNG became half the size. Since all compression used is lossless, this must signify that the original PNGs from FFMPEG must have a very low compression quality, which is fine.\
The TIFF images are very large, ~20% less than uncompressed size. nvTIFF offers no control over LZW compression quality, and it appears to be set for low quality, making it all the more strange that encoding is quite slow. Honestly, this is disappointing; much room to improve on NVIDIA's side when it comes to encoding here.

https://docs.nvidia.com/cuda/video-decoder/index.html\
https://developer.nvidia.com/video-codec-sdk\
https://ffmpeg.org/documentation.html

NVIDIA has tools for video encoding and decoding as well. For decoding, there's NVDEC (formerly NVCUVID, name changed due to encoding becoming important as well). For encoding, there's NVENC. These are decoders and encoders for video codecs. Video encoding and decoding is intensive, so hardware is dedicated to them, similar to nvJPEG. NVDEC and NVENC are essentially libraries that directly interface with the NVDEC and NVENC hardware. An NVIDIA accelerator may have multiple such encoders and decoders, e.g. an A100 has 5 NVDEC units. NVDEC and NVENC are not intended to be practically used for say decoding an h.264 MP4. They just implement codecs, intended to be used by other libraries. NVDEC and NVENC are extremely low level because of this, essentially defining a number of functions and enums to directly access NVDEC and NVENC units. Moreover, video formats are highly complicated. So it makes no sense to try and use NVDEC and NVENC directly. The FFMPEG project provides libraries for encoding and decoding videos that are intended for practical use, like decoding an h.264 MP4, and libavcodec in particular (one of the FFMPEG libraries) can utilize NVENC and NVDEC. The target audience for NVDEC and NVENC is e.g. people implementing libraries like FFMPEG, not us.

There were no issues using the FFMPEG libraries, they work wonderfully. They are C libraries of course, using them in CUDA for simplicity's sake is ok, but required some unintended casts. Because most videos are NV12, we also implemented NV12 to RGB24 conversion, via libswscale, which worked fine. Because FFMPEG is already quite elegant with how it handles data, there isn't much to gain from functional modularization. So we just put the entire video decoding process in the main function. We didn't do a microbenchmark, we instead decoder an entire high bitrate 4K 2 hour video. This took 10 minutes or so, with the GPU clearly working relatively hard in terms of memory usage and bandwidth, around 30%, but maximum out video decoding obviously. The video was HEVC encoded. The hardware seems more suited to HEVC (a few times faster, normalized to file size), which is quite interesting, because HEVC is a much more complicated codec than H.264. But it also makes sense to put more effort into future codecs. It was useful to write a separate program to list the available codecs, because while FFMPEG lists it, that's not necessarily the same thing the dev version of libavcodec has access to, and because we c

The last thing to implement is TIFF to NV12 HEVC in an mp4 container, which we haven't done, due to lack of interest. One expected complication here is that the NVCUVID encoder likely requires some sort of padding (for general resolutions), whereas nvTIFF uses no padding. Another challenge is that it would be ideal for the image buffers to stay on the GPU after TIFF decoding, which is probably tricky, if at all possible, in the FFMPEG interface to CUVID.
